{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def accuracy( C ):\n",
    "    ''' Compute accuracy given Numpy array confusion matrix C. Returns a floating point value '''\n",
    "    a = 0\n",
    "    for i in range(4):\n",
    "      a += C[i][i]\n",
    "    \n",
    "    return a/np.sum(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get batches for each epoch\n",
    "def get_batches(inputs, targets, batch_size, shuffle=True):\n",
    "    \"\"\"Divide a dataset into mini-batches of a given size. This is a'generator'.\"\"\"\n",
    "    \n",
    "    if inputs.shape[0] % batch_size != 0:\n",
    "        raise RuntimeError('The number of data points must be a multiple of the batch size.')\n",
    "    num_batches = inputs.shape[0] // batch_size\n",
    "\n",
    "    if shuffle:\n",
    "        idxs = np.random.permutation(inputs.shape[0])\n",
    "        inputs = inputs[idxs, :]\n",
    "        targets = targets[idxs]\n",
    "\n",
    "    for m in range(num_batches):\n",
    "        yield inputs[m*batch_size:(m+1)*batch_size, :], \\\n",
    "              targets[m*batch_size:(m+1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(inputs, targets, ratio=0.2, shuffle=True):\n",
    "    num_train = int(inputs.shape[0]*(1-ratio))\n",
    "    indices = np.arange(inputs.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    X_train = inputs[indices[:num_train]]\n",
    "    Y_train = targets[indices[:num_train]]\n",
    "    X_test = inputs[indices[num_train:]]\n",
    "    Y_test = targets[indices[num_train:]]\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (h1): Linear(in_features=164, out_features=1058, bias=True)\n",
      "  (o): Linear(in_features=1058, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.h1 = nn.Linear(164, 1058)\n",
    "        self.o = nn.Linear(1058, 4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h1(x))\n",
    "        x = F.softmax(self.o(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "loss_f = F.cross_entropy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data and labels\n",
    "with open(\"dataSmaller.pk\", \"rb\") as f:\n",
    "    X, Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 164), (80000,), (20000, 164), (20000,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "X_train = Variable(torch.from_numpy(X_train).float())\n",
    "Y_train = Variable(torch.from_numpy(Y_train).long())\n",
    "X_test = Variable(torch.from_numpy(X_test).float())\n",
    "Y_test = Variable(torch.from_numpy(Y_test).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 100\n",
    "lr = 0.0002\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "batch_size = 1000\n",
    "loss_report = 10\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    for i, (input_batch, target_batch) in enumerate(get_batches(X_train, Y_train, batch_size)):\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        output = net(input_batch)\n",
    "        loss = loss_f(output, target_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "        if (i+1)%loss_report == 0:\n",
    "            print(\"Batch:\", i+1, \"loss:\",loss.item())\n",
    "    # validation error\n",
    "    with torch.no_grad():\n",
    "        y_predict = net(X_test)\n",
    "        loss_t = loss_f(y_predict, Y_test)\n",
    "#         if loss_t < lbest:\n",
    "#             lbest = loss_t\n",
    "#             bestp = net.state_dict()\n",
    "        y_p = torch.argmax(y_predict, dim = 1).numpy()\n",
    "        c2 = confusion_matrix(Y_test, y_p)\n",
    "        print(\"test loss:\",loss_t.item(), \"acc :\", accuracy(c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
